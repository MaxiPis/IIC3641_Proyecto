{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Zona de import"
      ],
      "metadata": {
        "id": "w7IS-hiFI_KU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n18irTDH6HS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph transformer layer"
      ],
      "metadata": {
        "id": "IlLqqMFGJGnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphTransformerLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(\n",
        "            embed_dim=d_model,\n",
        "            num_heads=n_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=False  # MultiheadAttention usa (L, B, D)\n",
        "        )\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, adj_mask=None): # ojo que adj_mask es un tensor (N,N)\n",
        "        #x: tensor (B, N, d_model)\n",
        "        #adj_mask: tensor (N, N) con 0 en aristas válidas y -inf donde NO hay arista\n",
        "        #(misma para todo el batch, grafo estructural fijo)\n",
        "\n",
        "        B, N, D = x.shape\n",
        "\n",
        "        # MultiheadAttention espera (L, B, D)\n",
        "        x_t = x.permute(1, 0, 2)  # (N, B, D)\n",
        "\n",
        "        # Self-attention\n",
        "        attn_output, attn_weights = self.self_attn(\n",
        "            x_t, x_t, x_t, attn_mask=adj_mask\n",
        "        )\n",
        "        x_t = x_t + self.dropout(attn_output)\n",
        "        x_t = self.norm1(x_t)\n",
        "\n",
        "        # feed-forward\n",
        "        ff = self.linear2(F.relu(self.linear1(x_t)))\n",
        "        x_t = x_t + self.dropout(ff)\n",
        "        x_t = self.norm2(x_t)\n",
        "\n",
        "        # devolvemos el (B, N, D)\n",
        "        out = x_t.permute(1, 0, 2)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "q26GIV0VJMRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder de los nodos"
      ],
      "metadata": {
        "id": "zHbvzQjALQpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeEncoder(nn.Module):\n",
        "    def __init__(self, d_dyn, d_static, d_img, d_model):\n",
        "        super().__init__()\n",
        "        self.lin_x = nn.Linear(d_dyn, d_model)\n",
        "        self.lin_e = nn.Linear(d_static, d_model)\n",
        "        self.lin_I = nn.Linear(d_img, d_model)\n",
        "\n",
        "    def forward(self, X_t, E, I_t):\n",
        "        #X_t: (B, N, d_dyn) features dinámicas en tiempo t\n",
        "        #E:   (B, N, d_static) features estáticas del nodo (anatómicas, tipo)\n",
        "        #I_t: (B, d_img) embedding del frame en t\n",
        "\n",
        "        B, N, _ = X_t.shape\n",
        "\n",
        "        h_x = self.lin_x(X_t)# (B, N, d_model) ambos h\n",
        "        h_e = self.lin_e(E)\n",
        "\n",
        "        # broadcast de I_t a todos los nodos\n",
        "        I_expanded = I_t.unsqueeze(1).expand(B, N, -1)  #(B, N, d_img)\n",
        "        h_I = self.lin_I(I_expanded)  # (B, N, d_model)\n",
        "\n",
        "        H0 = h_x + h_e + h_I\n",
        "        return H0\n"
      ],
      "metadata": {
        "id": "64JC51NGLSv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# graph recurrent"
      ],
      "metadata": {
        "id": "iQRcb5SmLtec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentGraphTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_dyn,        # dim features dinámicas X\n",
        "        d_static,     # dim features estáticas E\n",
        "        d_img,        # dim embeddings de frame I\n",
        "        d_model=256,\n",
        "        n_heads=4,\n",
        "        n_layers=3,\n",
        "        d_ff=512,\n",
        "        dropout=0.1,\n",
        "        d_out=1 # esto es para que la salida se active\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.encoder = NodeEncoder(d_dyn, d_static, d_img, d_model) # Encoder nodos (X + E + I)\n",
        "\n",
        "        # Stack de capas Graph Transformer\n",
        "        self.layers = nn.ModuleList([\n",
        "            GraphTransformerLayer(d_model, n_heads, d_ff, dropout)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        # Decoder para predecir\n",
        "        self.decoder = nn.Sequential(nn.Linear(d_model, d_model), nn.ReLU(), nn.Linear(d_model, d_out))\n",
        "\n",
        "    def forward(self, X, E, I, adj=None):\n",
        "        #X:  (B, T, N, d_dyn) es trayectoria de features dinámicos\n",
        "        #E:  (B, N, d_static) es las features estáticas de nodos\n",
        "        #I:  (B, T, d_img) embeddings de frame por tiempo\n",
        "        #adj: (N, N) o None matriz de adyacencia (0/1)\n",
        "\n",
        "        #Returna preds: (B, T-1, N, d_out) con predicciones de X_{t+1}\n",
        "        B, T, N, d_dyn = X.shape\n",
        "\n",
        "        if adj is not None:\n",
        "            # adj: 1 arista, 0 no arista.\n",
        "            adj = adj.to(X.device)\n",
        "            attn_mask = (adj == 0).float() * -1e9  # (N, N)\n",
        "        else:\n",
        "            attn_mask = None\n",
        "        H_prev = torch.zeros(B, N, self.d_model, device=X.device)\n",
        "        preds = []\n",
        "\n",
        "        # Recorremos tiempos t = 0..T-2 para predecir X_{t+1}\n",
        "        for t in range(T - 1):\n",
        "            X_t = X[:, t]       # (B, N, d_dyn)\n",
        "            I_t = I[:, t]       # (B, d_img)\n",
        "\n",
        "            H0_t = self.encoder(X_t, E, I_t)  # (B, N, d_model)\n",
        "            H_t = H0_t + H_prev # hacemos la suma\n",
        "\n",
        "            #pasamos por L capas del graph transformer\n",
        "            for layer in self.layers:\n",
        "                H_t = layer(H_t, adj_mask=attn_mask)\n",
        "\n",
        "            #Prediccion siguiente\n",
        "            Y_t = self.decoder(H_t)  # (B, N, d_out)\n",
        "            preds.append(Y_t.unsqueeze(1))  # (B, 1, N, d_out)\n",
        "            H_prev = H_t #actualizamos\n",
        "        preds = torch.cat(preds, dim=1)  # (B, T-1, N, d_out)\n",
        "        return preds\n"
      ],
      "metadata": {
        "id": "J4kaFhPZL8eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Función de entrenamiento"
      ],
      "metadata": {
        "id": "vkuUQJkIOR3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_recurrent_graph_transformer(model, X, E, I, adj, num_epochs=50, lr=1e-3,\n",
        "    batch_size=None, loss_fn=None, target_feature_idx=0, verbose=True):\n",
        "    \"\"\"\n",
        "    Entrena un RecurrentGraphTransformer para predecir X_{t+1} a partir de X_t, E, I_t.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    model : nn.Module\n",
        "        Instancia de RecurrentGraphTransformer.\n",
        "    X : torch.Tensor\n",
        "        Tensor de shape (B, T, N, d_dyn) con la historia de features dinámicos.\n",
        "    E : torch.Tensor\n",
        "        Tensor de shape (B, N, d_static) con features estáticas de cada nodo.\n",
        "    I : torch.Tensor\n",
        "        Tensor de shape (B, T, d_img) con embeddings de frame por tiempo.\n",
        "    adj : torch.Tensor\n",
        "        Tensor de shape (N, N) con la matriz de adyacencia (0/1).\n",
        "    num_epochs : int\n",
        "        Número de épocas de entrenamiento.\n",
        "    lr : float\n",
        "        Learning rate del optimizador Adam.\n",
        "    batch_size : int or None\n",
        "        Tamaño de batch. Si es None, usa todo el batch de una vez.\n",
        "    loss_fn : callable or None\n",
        "        Función de pérdida. Si es None, usa BCEWithLogitsLoss.\n",
        "    target_feature_idx : int\n",
        "        Índice de la feature de X que usaremos como target para X_{t+1}.\n",
        "        Por ejemplo, si X tiene d_dyn>1 y la activación binaria está en el canal 0.\n",
        "    verbose : bool\n",
        "        Si True, imprime la pérdida por época.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    losses : list[float]\n",
        "        Lista con la pérdida promedio de cada época.\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "    X = X.to(device)\n",
        "    E = E.to(device)\n",
        "    I = I.to(device)\n",
        "    adj = adj.to(device)\n",
        "\n",
        "    B, T, N, d_dyn = X.shape\n",
        "\n",
        "    if batch_size is None:\n",
        "        batch_size = B\n",
        "\n",
        "    if loss_fn is None:\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        perm = torch.randperm(B, device=device)\n",
        "\n",
        "        for start in range(0, B, batch_size):\n",
        "            end = min(start + batch_size, B)\n",
        "            idx = perm[start:end]\n",
        "\n",
        "            X_b = X[idx]      # (b, T, N, d_dyn)\n",
        "            E_b = E[idx]      # (b, N, d_static)\n",
        "            I_b = I[idx]      # (b, T, d_img)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Predicciones del siguiente elemento\n",
        "            preds = model(X_b, E_b, I_b, adj=adj)  # (b, T-1, N, d_out)\n",
        "            target = X_b[:, 1:, :, target_feature_idx:target_feature_idx+1]  # (b, T-1, N, 1)\n",
        "            loss = loss_fn(preds, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            num_batches += 1\n",
        "        epoch_loss /= max(1, num_batches)\n",
        "        losses.append(epoch_loss)\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs} - loss: {epoch_loss:.4f}\")\n",
        "    return losses\n"
      ],
      "metadata": {
        "id": "Gc7PNyfAOTeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def evaluate_recurrent_graph_transformer(model, X, E, I, adj, batch_size=None, loss_fn=None,\n",
        "    target_feature_idx=0, threshold=0.5, verbose=True):\n",
        "    \"\"\"\n",
        "    Evalúa un RecurrentGraphTransformer en un conjunto de validación/test.\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    X = X.to(device)\n",
        "    E = E.to(device)\n",
        "    I = I.to(device)\n",
        "    adj = adj.to(device)\n",
        "\n",
        "    B, T, N, d_dyn = X.shape\n",
        "    if batch_size is None:\n",
        "        batch_size = B\n",
        "    if loss_fn is None:\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_elements = 0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, B, batch_size):\n",
        "            end = min(start + batch_size, B)\n",
        "            idx = slice(start, end)\n",
        "\n",
        "            X_b = X[idx]\n",
        "            E_b = E[idx]\n",
        "            I_b = I[idx]\n",
        "            preds = model(X_b, E_b, I_b, adj=adj)\n",
        "            target = X_b[:, 1:, :, target_feature_idx:target_feature_idx+1]\n",
        "            loss = loss_fn(preds, target)\n",
        "            total_loss += loss.item()\n",
        "            logits = preds\n",
        "            probs = torch.sigmoid(logits)\n",
        "            pred_bin = (probs >= threshold).float()\n",
        "            correct = (pred_bin == target).sum().item()\n",
        "            elements = target.numel()\n",
        "            total_correct += correct\n",
        "            total_elements += elements\n",
        "            num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / max(1, num_batches)\n",
        "    accuracy = total_correct / max(1, total_elements)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[Eval] loss: {avg_loss:.4f}, accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return {\"loss\": avg_loss, \"accuracy\": accuracy}\n"
      ],
      "metadata": {
        "id": "9sTWXHA0QI22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# como debería usarse"
      ],
      "metadata": {
        "id": "8H-ZvuGmO5pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = RecurrentGraphTransformer(\n",
        "    d_dyn=X_train.shape[-1],\n",
        "    d_static=E_train.shape[-1],\n",
        "    d_img=I_train.shape[-1],\n",
        "    d_model=256,\n",
        "    n_heads=4,\n",
        "    n_layers=3,\n",
        "    d_ff=512,\n",
        "    dropout=0.1,\n",
        "    d_out=1\n",
        ").to(device)\n",
        "\n",
        "# entrenamiento\n",
        "train_losses = train_recurrent_graph_transformer(\n",
        "    model,\n",
        "    X_train,\n",
        "    E_train,\n",
        "    I_train,\n",
        "    adj,\n",
        "    num_epochs=50,\n",
        "    lr=1e-3,\n",
        "    batch_size=8,\n",
        "    target_feature_idx=0,\n",
        ")\n",
        "\n",
        "# evaluación\n",
        "metrics_val = evaluate_recurrent_graph_transformer(\n",
        "    model,\n",
        "    X_val,\n",
        "    E_val,\n",
        "    I_val,\n",
        "    adj,\n",
        "    batch_size=8,\n",
        "    target_feature_idx=0,\n",
        "    threshold=0.5,\n",
        ")\n",
        "\n",
        "print(\"Métricas validación:\", metrics_val)\n"
      ],
      "metadata": {
        "id": "gxnRQhORO7hU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}